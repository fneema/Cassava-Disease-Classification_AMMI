{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jerofad/Cassava-Disease-
Classification_AMMI/blob/master/tf_starter_notebook.ipynb\" target=\"_parent\"><img \n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOzrpO0JMl8M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from fastai.vision import *\n",
    "import fastai\n",
    "from PIL import Image\n",
    "import shutil\n",
    "# import fastai\n",
    "# from fastai import vision\n",
    "\n",
    "!pip install pretrainedmodels\n",
    "import pretrainedmodels as pm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tv59drmCUlz8"
   },
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NWgwdvhMzhF"
   },
   "outputs": [],
   "source": [
    "# Colab's file access feature\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive',force_remount=True)\n",
    "# json_file = '/content/gdrive/My Drive/kaggle/kaggle.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6GwrRhLVVMG"
   },
   "outputs": [],
   "source": [
    "!mkdir .kaggle\n",
    "cd kaggle\\ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6NRLFFLMp7U"
   },
   "outputs": [],
   "source": [
    "# To get the API token from kaggle (kaggle.json file)\n",
    "!pip uninstall -y kaggle\n",
    "!pip install --upgrade pip\n",
    "!pip install kaggle==1.5.6\n",
    "!kaggle -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSyN_bRIOhIA"
   },
   "outputs": [],
   "source": [
    "#download data, will take 30-60 seconds\n",
    "!kaggle competitions download -c ammi-2020-convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16yqnvFPWUwj"
   },
   "outputs": [],
   "source": [
    "#unzip all data for usage, will take few minutes\n",
    "!unzip -qq ammi-2020-convnets.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4U3Ds6ypTKa"
   },
   "source": [
    "#USING FASTAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNb09Ep9pZb-"
   },
   "outputs": [],
   "source": [
    "# using defult transforms\n",
    "tfms = get_transforms(**transform_kwargs)\n",
    "\n",
    "# get the dataset\n",
    "data = (ImageList.from_folder('/train') #Where to find the data? -> in path and its subfolders\n",
    "        .split_by_rand_pct()              #How to split in train/valid? -> use the folders\n",
    "        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n",
    "        .transform(tfms, size=224)       #Data augmentation? -> use tfms with a size of 64\n",
    "        .add_test_folder('/test')\n",
    "        .databunch(bs = 64)) \n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8yKfvEibpZpB"
   },
   "outputs": [],
   "source": [
    "# specify the model you wanna use\n",
    "base_arch = lambda arg: pm.se_resnet50(num_classes=5, pretrained=None)\n",
    "learner = vision.cnn_learner(data, \n",
    "                             base_arch = base_arch, \n",
    "                             pretrained = False, \n",
    "                             metrics = vision.accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tKyk5nOq-Tm"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "learner.fit_one_cycle(3) # you can specify the lr if you want o.w will the deafult one\n",
    "\n",
    "# to save the model\n",
    "learner.save('model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ziEA3M2rsgO"
   },
   "outputs": [],
   "source": [
    "# Get the prediction\n",
    "\n",
    "predicted_probs, _ = learner.TTA(ds_type = fastai.basic_data.DatasetType.Test)\n",
    "predicted_probs, y = learner.get_preds(ds_type = fastai.basic_data.DatasetType.Test)\n",
    "\n",
    "_, predicted_classes = predicted_probs.max(dim=1)\n",
    "class_labels = np.array(['cbb','cbsd','cgm','cmd','healthy'])\n",
    "predicted_class_labels = class_labels[predicted_classes]\n",
    "\n",
    "filenames = np.array([item.name for item in data.test_ds.items])\n",
    "submission = (pd.DataFrame.from_dict({'Category': predicted_class_labels,'Id': filenames}))\n",
    "sub_file = '/content/gdrive/My Drive/Colab Notebooks/Kaggle/cassava_challenge/late_submission_pseudo_start_8.csv'\n",
    "submission.to_csv(sub_file, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7h2iPWiWg2L"
   },
   "source": [
    "# USIN PYTORCH\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAyk1ZhXMl8R"
   },
   "outputs": [],
   "source": [
    "data_path = \"train/train\"\n",
    "test_path = \"test/test\"\n",
    "extraimage_path = \"extraimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlgeT6S_Ml8V"
   },
   "outputs": [],
   "source": [
    "# Transformations for both the training and testing data\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([ transforms.Resize(255),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "normalize = transforms.Normalize(mean=mean, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYa-UA2fMl8X"
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.classes = os.listdir(path)\n",
    "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
    "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
    "        self.transform = transform\n",
    "\n",
    "        files = []\n",
    "        for i, className in enumerate(self.classes):\n",
    "            for fileName in self.file_list[i]:\n",
    "                files.append([i, className, fileName])\n",
    "        self.file_list = files\n",
    "        files = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fileName = self.file_list[idx][2]\n",
    "        classCategory = self.file_list[idx][0]\n",
    "        im = Image.open(fileName)\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "            \n",
    "        return im.view(3, 224, 224), classCategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNLgq4gJMl8a"
   },
   "outputs": [],
   "source": [
    "train_data = CassavaDataset(data_path, transform=train_transforms)\n",
    "test_data = CassavaDataset(test_path, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUKH54WGMl8d"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1a1stTTMl8g"
   },
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "                                             sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "                                             sampler=valid_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe4ZQRJAMl8j"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Y1ZNVgFMl8m"
   },
   "outputs": [],
   "source": [
    "# Define Models \n",
    "\n",
    "def se_resnext50_32x4d(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.se_resnext50_32x4d(pretrained=pretrained)\n",
    "    return model\n",
    "\n",
    "model = se_resnext50_32x4d(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRKAkkFEMl8p"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new final layer with 5 classes\n",
    "model.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "num_ftrs = model.last_linear.in_features\n",
    "model.last_linear = torch.nn.Linear(num_ftrs, 5)\n",
    "if use_gpu:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyS3UTO0Ml8r"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g2eON6U3Ml8t"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
    "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
    "    \n",
    "    # Make sure model is in training mode.\n",
    "    model.train()\n",
    "    \n",
    "    # Move model to the device (CPU or GPU).\n",
    "    model.to(device)\n",
    "    \n",
    "    # Exponential moving average of the loss.\n",
    "    ema_loss = None\n",
    "    \n",
    "    # Loop over epochs.\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "      # Loop over data.\n",
    "      for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            \n",
    "          # Forward pass.\n",
    "          output = model(data.to(device))\n",
    "          loss = criterion(output.to(device), target.to(device))\n",
    "          \n",
    "          # Backward pass.\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "          # NOTE: It is important to call .item() on the loss before summing.\n",
    "          if ema_loss is None:\n",
    "            ema_loss = loss.item()\n",
    "          else:\n",
    "            ema_loss += (loss.item() - ema_loss) * 0.01 \n",
    "          \n",
    "      # Print out progress the end of epoch.\n",
    "      print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT77JPeiMl8w"
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader):\n",
    "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
    "    # Make sure the model is in evaluation mode.\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    # We do not need to maintain intermediate activations while testing.\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Loop over test data.\n",
    "        for data, target in data_loader:\n",
    "          \n",
    "            # Forward pass.\n",
    "            output = model(data.to(device))\n",
    "            \n",
    "            # Get the label corresponding to the highest predicted probability.\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # Count number of correct predictions.\n",
    "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    # Print test accuracy.\n",
    "    percent = 100. * correct / len(data_loader.dataset)\n",
    "    print(f'Accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqHualAFMl8y"
   },
   "outputs": [],
   "source": [
    "train(model, criterion, train_loader, optimizer, num_epochs=1)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ja6XQr_xMl8z"
   },
   "outputs": [],
   "source": [
    "# load saved model to make predictions on test data\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YG-XEyzgMl82"
   },
   "outputs": [],
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "plpBUw-gMl84"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pytorch_starter_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
